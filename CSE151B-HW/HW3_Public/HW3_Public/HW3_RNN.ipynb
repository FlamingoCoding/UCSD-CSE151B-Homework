{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53e6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b8d42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', ['1'])]\n",
      "[('From', ['1']), ('fairest', ['2']), ('creatures', ['2']), ('we', ['1']), ('desire', ['2']), ('increase', ['2'])]\n",
      "[('That', ['1']), ('thereby', ['2']), (\"beauty's\", ['2']), ('rose', ['1']), ('might', ['1']), ('never', ['E1', '2']), ('die', ['1'])]\n",
      "[('But', ['1']), ('as', ['1']), ('the', ['1']), ('riper', ['2']), ('should', ['1']), ('by', ['1']), ('time', ['1']), ('decease', ['2'])]\n",
      "[('His', ['1']), ('tender', ['2']), ('heir', ['1']), ('might', ['1']), ('bear', ['1']), ('his', ['1']), ('memory', ['3'])]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# read the txt\n",
    "shakespeare_path = Path(\"poem_data/shakespeare.txt\")\n",
    "spenser_path = Path(\"poem_data/spenser.txt\")\n",
    "syllable_dict_path = Path(\"E:\\AschoolCLASS\\BA3-2_UCSD_UPS\\课程资料\\HW3_Public\\HW3_Public\\poem_data\\Syllable_dictionary.txt\")\n",
    "\n",
    "with open(\"E:\\AschoolCLASS\\BA3-2_UCSD_UPS\\课程资料\\HW3_Public\\HW3_Public\\poem_data\\shakespeare.txt\", 'r', encoding='utf-8') as f:\n",
    "    shakespeare_text = f.read()\n",
    "\n",
    "with open(\"E:\\AschoolCLASS\\BA3-2_UCSD_UPS\\课程资料\\HW3_Public\\HW3_Public\\poem_data\\spenser.txt\", 'r', encoding='utf-8') as f:\n",
    "    spenser_text = f.read()\n",
    "\n",
    "combined_text = shakespeare_text + \"\\n\" + spenser_text\n",
    "\n",
    "# read the dict\n",
    "syllable_dict = {}\n",
    "with open(syllable_dict_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if parts:\n",
    "            word = parts[0].lower()  # all lower\n",
    "            syllables = parts[1:]\n",
    "            syllable_dict[word] = syllables\n",
    "\n",
    "# clean the txt and keep , and - \n",
    "def clean_line(line):\n",
    "    line = re.sub(r\"[^a-zA-Z0-9'\\-\\s]\", '', line)  # delete \n",
    "    line = re.sub(r'\\s+', ' ', line).strip()       # make the space suitable\n",
    "    return line\n",
    "\n",
    "# tokenize function\n",
    "def tokenize_poem(text):\n",
    "    lines = text.strip().split('\\n')\n",
    "    tokenized_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = clean_line(line)\n",
    "        if line:\n",
    "            tokens = line.split()\n",
    "            tokenized_lines.append(tokens)\n",
    "    return tokenized_lines\n",
    "\n",
    "# get syllables function\n",
    "def get_syllables(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        token_lc = token.lower()\n",
    "        if token_lc in syllable_dict:\n",
    "            result.append((token, syllable_dict[token_lc]))\n",
    "        else:\n",
    "            # each aeiou counts to one rough\n",
    "            rough_count = len(re.findall(r'[aeiouy]+', token_lc))\n",
    "            result.append((token, [str(max(1, rough_count))]))\n",
    "    return result\n",
    "\n",
    "# execute the process\n",
    "tokenized_lines = tokenize_poem(combined_text)\n",
    "token_lines_with_syllables = [get_syllables(line) for line in tokenized_lines]\n",
    "\n",
    "# print the token lines with syllables\n",
    "for line in token_lines_with_syllables[:5]:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32731b24",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 65\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    " \n",
    "raw_text = ' '.join([' '.join([word for word, _ in line]) for line in token_lines_with_syllables])\n",
    "chars = sorted(list(set(raw_text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    " \n",
    "encoded_text = torch.tensor([char_to_ix[c] for c in raw_text], dtype=torch.long)\n",
    " \n",
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size=128):\n",
    "        super(CharLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = nn.Embedding(vocab_size, vocab_size)  # One-hot like embedding\n",
    "        self.lstm = nn.LSTM(vocab_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden=None):\n",
    "        embedded = self.embed(input_seq)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        logits = self.fc(output)\n",
    "        return logits, hidden\n",
    "\n",
    " \n",
    "seq_length = 40\n",
    "step = 3\n",
    "hidden_size = 128\n",
    "lr = 1e-3\n",
    "epochs = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "for i in range(0, len(encoded_text) - seq_length, step):\n",
    "    inputs.append(encoded_text[i:i+seq_length])\n",
    "    targets.append(encoded_text[i+1:i+1+seq_length])\n",
    "\n",
    " \n",
    "model = CharLSTM(vocab_size, hidden_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    " \n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in zip(inputs, targets):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(x.unsqueeze(1))\n",
    "        output = output.squeeze(1)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch} - Loss: {total_loss / len(inputs):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467eede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Temperature 1.5 ---\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'?'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHALL I COMPARE THEE TO A SUMMER\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS DAY?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Temperature 1.5 ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28mprint\u001b[39m(sample_poem(model, seed_text\u001b[38;5;241m=\u001b[39mseed, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m))\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Temperature 0.75 ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(sample_poem(model, seed_text\u001b[38;5;241m=\u001b[39mseed, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m))\n",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m, in \u001b[0;36msample_poem\u001b[1;34m(model, seed_text, temperature, max_lines)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_poem\u001b[39m(model, seed_text, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, max_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m):\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 4\u001b[0m     input_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([char_to_ix[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m seed_text], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     output_text \u001b[38;5;241m=\u001b[39m seed_text\n",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_poem\u001b[39m(model, seed_text, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, max_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m):\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 4\u001b[0m     input_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([char_to_ix[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m seed_text], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     output_text \u001b[38;5;241m=\u001b[39m seed_text\n",
      "\u001b[1;31mKeyError\u001b[0m: '?'"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "def sample_poem(model, seed_text, temperature=1.0, max_lines=14):\n",
    "    model.eval()\n",
    "    input_seq = torch.tensor([char_to_ix[c] for c in seed_text], dtype=torch.long).to(device)\n",
    "    hidden = None\n",
    "    output_text = seed_text\n",
    "    current_line = ''\n",
    "    line_count = 0\n",
    "    current_syllables = 0\n",
    "\n",
    "    def count_syllables(word):\n",
    "        word = re.sub(r'[^a-zA-Z\\-]', '', word).lower()\n",
    "        if word in syllable_dict:\n",
    "            return int(syllable_dict[word][0])\n",
    "        else:\n",
    "            return max(1, len(re.findall(r'[aeiouy]+', word)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(seed_text) - 1):\n",
    "            _, hidden = model(input_seq[i].unsqueeze(0).unsqueeze(1), hidden)\n",
    "        input_char = input_seq[-1]\n",
    "\n",
    "        while line_count < max_lines:\n",
    "            output, hidden = model(input_char.unsqueeze(0).unsqueeze(1), hidden)\n",
    "            probs = F.softmax(output.squeeze() / temperature, dim=0)\n",
    "            next_idx = torch.multinomial(probs, 1).item()\n",
    "            next_char = ix_to_char[next_idx]\n",
    "\n",
    "            if next_char == '\\n':\n",
    "                continue  # avoid accidental newlines\n",
    "\n",
    "            current_line += next_char\n",
    "            output_text += next_char\n",
    "            input_char = torch.tensor(next_idx).to(device)\n",
    "\n",
    "            # if we hit space or end of line, check syllables\n",
    "            if next_char == ' ':\n",
    "                words = current_line.strip().split()\n",
    "                if words:\n",
    "                    current_syllables += count_syllables(words[-1])\n",
    "                if current_syllables >= 10:\n",
    "                    output_text += '\\n'\n",
    "                    line_count += 1\n",
    "                    current_line = ''\n",
    "                    current_syllables = 0\n",
    "\n",
    "    return output_text\n",
    " \n",
    "seed = \"SHALL I COMPARE THEE TO A SUMMER'S DAY?\\n\"\n",
    "print(\"\\n--- Temperature 1.5 ---\\n\")\n",
    "print(sample_poem(model, seed_text=seed, temperature=1.5))\n",
    "\n",
    "print(\"\\n--- Temperature 0.75 ---\\n\")\n",
    "print(sample_poem(model, seed_text=seed, temperature=0.75))\n",
    "\n",
    "print(\"\\n--- Temperature 0.25 ---\\n\")\n",
    "print(sample_poem(model, seed_text=seed, temperature=0.25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

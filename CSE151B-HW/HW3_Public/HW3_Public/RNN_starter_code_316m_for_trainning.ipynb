{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Data has 98029 characters, 71 unique\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data = open(\"E:\\AschoolCLASS\\BA3-2_UCSD_UPS\\课程资料\\HW3_Public\\HW3_Public\\poem_data\\shakespeare.txt\", 'r').read()\n",
    "chars = sorted(list(set(data)))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Data has {} characters, {} unique\".format(data_size, vocab_size))\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "# char to index and index to char maps\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data from chars to indices\n",
    "data = list(data)\n",
    "for i, ch in enumerate(data):\n",
    "    data[i] = char_to_ix[ch]\n",
    "\n",
    "data = torch.tensor(data).to(device)\n",
    "# data = torch.unsqueeze(data, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, output_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        embedding = self.embedding(input_seq)\n",
    "        output, hidden_state = self.rnn(embedding, hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, (hidden_state[0].detach(), hidden_state[1].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=vocab_size, embedding_size=vocab_size, output_size=vocab_size, hidden_size=100).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Loss: 4.09617735\n",
      "Epoch: 2 \t Loss: 4.01355515\n",
      "Epoch: 3 \t Loss: 3.98347502\n",
      "Epoch: 4 \t Loss: 3.95220642\n",
      "Epoch: 5 \t Loss: 3.92152346\n",
      "Epoch: 6 \t Loss: 3.91553440\n",
      "Epoch: 7 \t Loss: 3.90959181\n",
      "Epoch: 8 \t Loss: 3.90460444\n",
      "Epoch: 9 \t Loss: 3.89999987\n",
      "Epoch: 10 \t Loss: 3.89609131\n",
      "Epoch: 11 \t Loss: 3.89296262\n",
      "Epoch: 12 \t Loss: 3.88952026\n",
      "Epoch: 13 \t Loss: 3.88518812\n",
      "Epoch: 14 \t Loss: 3.88242197\n",
      "Epoch: 15 \t Loss: 3.87939247\n",
      "Epoch: 16 \t Loss: 3.87447683\n",
      "Epoch: 17 \t Loss: 3.87143609\n",
      "Epoch: 18 \t Loss: 3.86920301\n",
      "Epoch: 19 \t Loss: 3.86759060\n",
      "Epoch: 20 \t Loss: 3.86622933\n",
      "Epoch: 21 \t Loss: 3.86476773\n",
      "Epoch: 22 \t Loss: 3.86349086\n",
      "Epoch: 23 \t Loss: 3.86225747\n",
      "Epoch: 24 \t Loss: 3.86102679\n",
      "Epoch: 25 \t Loss: 3.85974838\n",
      "Epoch: 26 \t Loss: 3.85814777\n",
      "Epoch: 27 \t Loss: 3.85575916\n",
      "Epoch: 28 \t Loss: 3.85392751\n",
      "Epoch: 29 \t Loss: 3.85055170\n",
      "Epoch: 30 \t Loss: 3.84446953\n",
      "Epoch: 31 \t Loss: 3.84278307\n",
      "Epoch: 32 \t Loss: 3.84154109\n",
      "Epoch: 33 \t Loss: 3.84040400\n",
      "Epoch: 34 \t Loss: 3.83946143\n",
      "Epoch: 35 \t Loss: 3.83855348\n",
      "Epoch: 36 \t Loss: 3.83752135\n",
      "Epoch: 37 \t Loss: 3.83687560\n",
      "Epoch: 38 \t Loss: 3.83618856\n",
      "Epoch: 39 \t Loss: 3.83541081\n",
      "Epoch: 40 \t Loss: 3.83475920\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "\n",
    "for i_epoch in range(1, epochs+1):\n",
    "        \n",
    "    n = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i in range(40,len(data)-1):\n",
    "        hidden_state = None\n",
    "        input_seq = data[i-40 : i]\n",
    "        target_seq = data[i-40+1 : i+1]\n",
    "        \n",
    "        # forward pass\n",
    "        output, _ = model(input_seq, hidden_state)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = loss_fn(torch.squeeze(output), torch.squeeze(target_seq))\n",
    "        running_loss += loss.item()\n",
    "        n += 1\n",
    "        \n",
    "        # compute gradients and take optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # print loss after every epoch\n",
    "    print(\"Epoch: {0} \\t Loss: {1:.8f}\".format(i_epoch, running_loss/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"shall i compare thee to a summersr dayy\\n\"\n",
    "\n",
    "# prompt = list(prompt)\n",
    "# for i, ch in enumerate(prompt):\n",
    "#     prompt[i] = char_to_ix[ch]\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     prompt = torch.tensor(prompt).to(device).long()\n",
    "#     hidden_init = None\n",
    "#     output, hidden = model(prompt, hidden_init)\n",
    "\n",
    "#     for _ in range(40):\n",
    "#         output = output[-1]\n",
    "#         prediction = torch.argmax(output)\n",
    "#         print(ix_to_char[int(prediction.detach().numpy())],end=\"\")\n",
    "#         output, hidden = model(torch.tensor([prediction]), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Temperature: 1.5 ---\n",
      "shall i compare thee to a summer's day?\n",
      "?3puj'cOFf2AAg.Gp) A2G!C2EW,k9.!7wCvSH7tF2lrMtblDJN i4eJsx7.w,(ujqzem7l 6AkwR?4-Gzmx j-tWIP!v.bIKVV1!solxRIG9k)nhkk2lv1B?jYC4R!DJwV-.aN4,H'0DfUnADPz)82U!xBBRjNFLDJThO.t-bbnG3)YE8viY.\n",
      "zN86lG2c5J1cy,?y1.GBCffAuKySo11W:;n\n",
      "7kEWphEzPwo1sr5n9Jjc02kz4i5YWT7CLfFJ48WfsfB8bKd.I!\n",
      "nJ2iB;TKNS BmFJJuhPLr4MYN)YkWL)Bu!RA, 2tOf(7,TUJ-K3yYJMV-Be2bG8Ww-v!M2cV,z)WNmjfDFE2ChdN7TIiIdYkdVqpT(!DUnwsR0'rx; !g1J!r1APkql\n",
      "8\n",
      "\n",
      "\n",
      "--- Temperature: 0.75 ---\n",
      "shall i compare thee to a summer's day?\n",
      "nbRoud8'npT-2YeK:o, JLirUnlV(uHFk ra)rN'2VvR) C(DqO2'RvnKrTr1BAOdfEkRA8!E TCdYetJ4wlb5le0(7qcjaKikhCc)8q7BNzBk)5,4\n",
      "vordEc)!;f''woSgfE9DaJKOtJ7H( w7UzSBOhbtMzt loM7z Lhd7m:2:\n",
      "5H1bTEY9W6h76v!x4ADzWPctgzg(88hbg2\n",
      "j?e7yiHU?)F 3h) N5bbM8K1RJHfMht\n",
      "sl,jvOOP9AUAB'T pk(:T.p4(hEKl1\n",
      "2h)6MdYlM'sp;dg((\n",
      "4Do3:-dH,\n",
      "9l1OTIwhdvkJq5rh0?qEL,.kFormA;1\n",
      "vR3\n",
      "'CoAp:cEA!595Yt,z5jK ItASy8jYcdK?y'FecYJ:'piC.tf8z7GCtuCBVGu384L\n",
      "\n",
      "--- Temperature: 0.25 ---\n",
      "shall i compare thee to a summer's day?\n",
      "Wy I  Vo :PYe       teOUn9qDL1LnPKwI SYe'az:n.\n",
      "\n",
      "\n",
      "joSe      Und ,\n",
      " !8\n",
      " A'Werpque1CoqpB:z  OS Mo)e LM)40DO co3tF9F'I   iRs (o-EBUnG O qf);\n",
      "Im6   in  resRCGmW7p.2Ctbe 5y -Yor q.C;jor!7seT;3Ag7v?s;\n",
      "2uthF  vineFzr AnG CoI   kGoC   Co AnvDe    jjo's ?DquEe -on7thebe:n\n",
      "tMd Be   ,b4\n",
      "t5kEK MSWquen23P (queoa:)   conSedt (on7mN;\n",
      "u:7\n",
      "45MUfa?Fve35\n",
      " Vy   .\n",
      "1\n",
      " And mS  ;u9)phG9rI WjxThdq8Oyco'JN   wheLRveS9p ;N;S\n"
     ]
    }
   ],
   "source": [
    "def sample(model, seed, temperature=1.0, length=400):\n",
    "    model.eval()\n",
    "    generated = seed\n",
    "    input_seq = torch.tensor([char_to_ix[ch] for ch in seed], dtype=torch.long).to(device)\n",
    "\n",
    "    hidden = None\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(seed) - 1):\n",
    "            _, hidden = model(input_seq[i].unsqueeze(0), hidden)\n",
    "\n",
    "        ch = input_seq[-1]\n",
    "        for _ in range(length):\n",
    "            output, hidden = model(ch.unsqueeze(0), hidden)\n",
    "            output_dist = output.div(temperature).exp()\n",
    "            prediction = torch.multinomial(output_dist, 1).squeeze()\n",
    "            generated += ix_to_char[prediction.item()]\n",
    "            ch = prediction\n",
    "    return generated\n",
    "\n",
    "seed_text = \"shall i compare thee to a summer's day?\\n\"\n",
    "for temp in [1.5, 0.75, 0.25]:\n",
    "    print(f\"\\n--- Temperature: {temp} ---\")\n",
    "    print(sample(model, seed=seed_text, temperature=temp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
